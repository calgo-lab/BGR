{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849a5387",
   "metadata": {},
   "source": [
    "## Inference with the best simple task solvers as a baseline for SoilNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed7ea49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/KInsektDaten/teo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../../../')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095ba374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_  # modifies the tensors in-place (vs clip_grad_norm)\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcaadd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./BGR')\n",
    "from bgr.soil.data.datasets import ImageTabularDataset\n",
    "from bgr.soil.data.horizon_tabular_data import HorizonDataProcessor\n",
    "import bgr.soil.modelling.depth.depth_models as bgr_mod\n",
    "from bgr.soil.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from bgr.soil.transforms import VerticalStripeCrop\n",
    "from bgr.soil.metrics import DepthMarkerLoss, TopKHorizonAccuracy, DepthIoULoss, depth_iou, precision_recall_at_k, top_k_accuracy\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from bgr.soil.utils import pad_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f74d31",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd40d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprocessor = HorizonDataProcessor(label_embeddings_path='./BGR/label_embeddings/all_horizons_embeddings_thirds.pickle')\n",
    "df = dataprocessor.load_processed_data()\n",
    "\n",
    "train_df, val_df, test_df = dataprocessor.multi_label_stratified_shuffle_split(df, train_val_test_frac=[0.6, 0.2, 0.2], random_state=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ee4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgr.soil.data.datasets import ImageTabularEnd2EndDataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "test_dataset = ImageTabularEnd2EndDataset(\n",
    "    dataframe=test_df,\n",
    "    normalize=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize with ImageNet statistics\n",
    "        ]),\n",
    "    label_column='Horizontsymbol_relevant',\n",
    "    geotemp_columns=dataprocessor.geotemp_img_infos[:-1], # without img path\n",
    "    tab_num_columns=['Steine'],\n",
    "    tab_categ_columns={key : value \n",
    "            for key, value in dataprocessor.tabulars_output_dim_dict.items() \n",
    "                if key in [\n",
    "                        'Bodenart',\n",
    "                        'Bodenfarbe',\n",
    "                        'Karbonat',\n",
    "                        'Humusgehaltsklasse',\n",
    "                        'Durchwurzelung'\n",
    "                    ]\n",
    "        }\n",
    ")\n",
    "\n",
    "test_loader = test_dataset.to_dataloader(batch_size=2, shuffle=True, num_workers=16, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52aed84",
   "metadata": {},
   "source": [
    "### Load individual Task Solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29cd2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task model paths\n",
    "depth_predictor_path = './model_output/simple_depths_maskedresnet_lstm_2025-05-12_14-44-21/model.pt'\n",
    "tabular_predictor_path = './model_output/simple_tabulars_geotmp_resnet_2025-05-08_13-39-13/model.pt'\n",
    "horizon_resnet_ce_path = './model_output/simple_horizon_classification_lstm_geotmp_mlp_tab_mlp_resnet_2025-05-12_15-30-38/model.pt'\n",
    "horizon_resnet_emb_path = './model_output/simple_horizon_classification_lstm_embed_geotmp_mlp_tab_mlp_resnet_2025-05-12_17-00-46/model.pt'\n",
    "\n",
    "# Note: The segment encoder (ResNet or PatchCNN) of the tabular predictor must match the one from the horizon predicotr\n",
    "horizon_cnn_ce_path = './model_output/simple_horizon_classification_lstm_geotmp_mlp_tab_mlp_2025-05-12_16-35-58/model.pt'\n",
    "horizon_cnn_emb_path = './model_output/simple_horizon_classification_lstm_embed_geotmp_mlp_tab_mlp_2025-05-12_18-45-21/model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987de27b",
   "metadata": {},
   "source": [
    "#### Depth Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52a1759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bgr.soil.modelling.depth.depth_models import SimpleDepthModelMaskedResNetLSTM\n",
    "depth_predictor = SimpleDepthModelMaskedResNetLSTM(\n",
    "            geo_temp_input_dim=len(dataprocessor.geotemp_img_infos) - 2, # without index and img path\n",
    "            geo_temp_output_dim=256,\n",
    "            image_encoder_output_dim=512,\n",
    "            max_seq_len=8,\n",
    "            stop_token=1.0,\n",
    "            rnn_hidden_dim=256\n",
    "        )\n",
    "depth_predictor.load_state_dict(torch.load(depth_predictor_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dae234",
   "metadata": {},
   "source": [
    "#### Tabular Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6957006f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bgr.soil.modelling.tabulars.tabular_models import SimpleTabularModel\n",
    "tabular_predictor = SimpleTabularModel(\n",
    "            tabular_output_dim_dict=dataprocessor.tabulars_output_dim_dict,\n",
    "            geotemp_input_dim=len(dataprocessor.geotemp_img_infos) - 2, # without index and img path\n",
    "            segment_encoder_output_dim=512,\n",
    "            geotemp_output_dim=256,\n",
    "            rnn_hidden_dim=1024,\n",
    "            num_lstm_layers=2,\n",
    "            predefined_random_patches=True\n",
    "        )\n",
    "tabular_predictor.load_state_dict(torch.load(tabular_predictor_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aca3f1",
   "metadata": {},
   "source": [
    "#### Horizon Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72bc43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same classes used with cosine and cross entropy loss, with custom CNN and ResNet segment encoders\n",
    "from bgr.soil.modelling.horizon.horizon_models import SimpleHorizonClassifierWithEmbeddingsGeotempsMLPTabMLP\n",
    "\n",
    "segments_tabular_categ_feature_columns = {key : value \n",
    "    for key, value in dataprocessor.tabulars_output_dim_dict.items() \n",
    "        if key in [\n",
    "                'Bodenart',\n",
    "                'Bodenfarbe',\n",
    "                'Karbonat',\n",
    "                'Humusgehaltsklasse',\n",
    "                'Durchwurzelung'\n",
    "            ]\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca5fab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_cnn_ce_predictor = SimpleHorizonClassifierWithEmbeddingsGeotempsMLPTabMLP(\n",
    "            geo_temp_input_dim=len(dataprocessor.geotemp_img_infos) - 2, # without index and img path\n",
    "            segments_tabular_input_dim=len(['Steine']) + sum(segments_tabular_categ_feature_columns.values()),\n",
    "            segment_encoder_output_dim=512,\n",
    "            segments_tabular_output_dim=256,\n",
    "            geo_temp_output_dim=256,\n",
    "            embedding_dim=len(dataprocessor.embeddings_dict['embedding']),\n",
    "            embed_horizons_linearly=False\n",
    "        )\n",
    "horizon_cnn_ce_predictor.load_state_dict(torch.load(horizon_cnn_ce_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62e169e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_cnn_emb_predictor = SimpleHorizonClassifierWithEmbeddingsGeotempsMLPTabMLP(\n",
    "            geo_temp_input_dim=len(dataprocessor.geotemp_img_infos) - 2, # without index and img path\n",
    "            segments_tabular_input_dim=len(['Steine']) + sum(segments_tabular_categ_feature_columns.values()),\n",
    "            segment_encoder_output_dim=512,\n",
    "            segments_tabular_output_dim=256,\n",
    "            geo_temp_output_dim=256,\n",
    "            embedding_dim=np.shape(dataprocessor.embeddings_dict['embedding'])[1],\n",
    "            embed_horizons_linearly=False\n",
    "        )\n",
    "horizon_cnn_emb_predictor.load_state_dict(torch.load(horizon_cnn_emb_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75946a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_resnet_ce_predictor = SimpleHorizonClassifierWithEmbeddingsGeotempsMLPTabMLP(\n",
    "            geo_temp_input_dim=len(dataprocessor.geotemp_img_infos) - 2, # without index and img path\n",
    "            segments_tabular_input_dim=len(['Steine']) + sum(segments_tabular_categ_feature_columns.values()),\n",
    "            segment_encoder_output_dim=512,\n",
    "            segments_tabular_output_dim=256,\n",
    "            geo_temp_output_dim=256,\n",
    "            embedding_dim=len(dataprocessor.embeddings_dict['embedding']),\n",
    "            embed_horizons_linearly=False,\n",
    "            predefined_random_patches=True\n",
    "        )\n",
    "horizon_resnet_ce_predictor.load_state_dict(torch.load(horizon_resnet_ce_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec0338fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizon_resnet_emb_predictor = SimpleHorizonClassifierWithEmbeddingsGeotempsMLPTabMLP(\n",
    "            geo_temp_input_dim=len(dataprocessor.geotemp_img_infos) - 2, # without index and img path\n",
    "            segments_tabular_input_dim=len(['Steine']) + sum(segments_tabular_categ_feature_columns.values()),\n",
    "            segment_encoder_output_dim=512,\n",
    "            segments_tabular_output_dim=256,\n",
    "            geo_temp_output_dim=256,\n",
    "            embedding_dim=np.shape(dataprocessor.embeddings_dict['embedding'])[1],\n",
    "            embed_horizons_linearly=False,\n",
    "            predefined_random_patches=True\n",
    "        )\n",
    "horizon_resnet_emb_predictor.load_state_dict(torch.load(horizon_resnet_emb_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9738f",
   "metadata": {},
   "source": [
    "### Inference on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a39b7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgr.soil.utils import extract_segments\n",
    "device = 'cuda'\n",
    "depth_predictor.to(device)\n",
    "tabular_predictor.to(device)\n",
    "horizon_resnet_ce_predictor.to(device)\n",
    "horizon_resnet_emb_predictor.to(device)\n",
    "depth_predictor.eval()\n",
    "tabular_predictor.eval()\n",
    "horizon_resnet_ce_predictor.eval()\n",
    "horizon_resnet_emb_predictor.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848a4690",
   "metadata": {},
   "source": [
    "#### Horizon, embedding loss, ResNet segment encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62816682",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou = 0.0\n",
    "horizon_correct = 0\n",
    "horizon_topk_correct = 0\n",
    "label_embeddings_tensor = torch.tensor(dataprocessor.embeddings_dict['embedding'], device=device).float()\n",
    "hor_topk = 5\n",
    "hor_topk_acc = lambda k : TopKHorizonAccuracy(label_embeddings_tensor, k=k)\n",
    "hor_class_average = 'macro'\n",
    "hor_possible_labels = list(range(label_embeddings_tensor.size(0)))\n",
    "all_horizon_labels = []\n",
    "all_topk_horizon_predictions = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    padded_images, image_mask, geotemp_features, padded_true_depths, padded_segments_tabulars_labels, padded_true_horizon_indices = batch\n",
    "    padded_images, image_mask, geotemp_features, padded_true_depths, padded_segments_tabulars_labels, padded_true_horizon_indices = (\n",
    "        padded_images.to(device),\n",
    "        image_mask.to(device),\n",
    "        geotemp_features.to(device),\n",
    "        padded_true_depths.to(device),\n",
    "        padded_segments_tabulars_labels.to(device),\n",
    "        padded_true_horizon_indices.to(device)\n",
    "    )\n",
    "    \n",
    "    ### TASK 1: Predict depth markers based on concatenated vector\n",
    "    pred_depth_markers = depth_predictor(padded_images, image_mask, geotemp_features[:, 1:]) # 'index' column not used in model\n",
    "    \n",
    "    ### TASK 2: Predict tabular features for each segment\n",
    "    # Crop image to segments\n",
    "    segments = extract_segments(padded_images, image_mask, pred_depth_markers,\n",
    "                                segments_random_patches=tabular_predictor.predefined_random_patches, # True, use ResNet segment encoder\n",
    "                                patch_cnn_segment_size=None, # not needed for ResNet segment encoder\n",
    "                                \n",
    "                                num_patches_per_segment=48,\n",
    "                                segment_random_patch_size=224, \n",
    "                                # Note: these two attributes are available in SegmentPatchesTabularDataset when training the simple tabular, \n",
    "                                # bot not in ImageTabularEnd2EndDataset when training SoilNet (there, they are attributes of the model itself)\n",
    "                                \n",
    "                                stop_token=depth_predictor.stop_token,\n",
    "                                max_seq_len=depth_predictor.depth_marker_predictor.max_seq_len)\n",
    "    \n",
    "    tabular_predictions = tabular_predictor(segments, geotemp_features[:, 1:]) # 'index' column not used in model\n",
    "    \n",
    "    ### TASK 3: Compute horizon embedding from the final concatenated vector\n",
    "    # Concatenate tabular features from dictionary\n",
    "    processed_tabular_features = torch.cat([tabular_predictions[key] for key in tabular_predictor.tabular_predictors.keys()], dim=-1)\n",
    "\n",
    "    padded_pred_horizon_embeddings = horizon_resnet_emb_predictor(segments, processed_tabular_features, geotemp_features[:, 1:]) \n",
    "    pred_horizon_embeddings   = torch.stack([pred for pred, lab in zip(padded_pred_horizon_embeddings.view(-1, padded_pred_horizon_embeddings.size(-1)), padded_true_horizon_indices.view(-1)) if lab != -1]).to(device)\n",
    "    pred_topk_horizon_indices = torch.topk(torch.matmul(pred_horizon_embeddings, label_embeddings_tensor.T), k=hor_topk, dim=1).indices\n",
    "    \n",
    "    # Normalize pred. embeddings for the cosine loss, true embeddings are already normalized\n",
    "    pred_horizon_embeddings = F.normalize(pred_horizon_embeddings, p=2, dim=1)\n",
    "\n",
    "    ### Compute metrics\n",
    "    # Update depth IoU separately\n",
    "    iou += depth_iou(pred_depth_markers, padded_true_depths, depth_predictor.stop_token)\n",
    "    \n",
    "    ## True horizons\n",
    "    true_horizon_embeddings = torch.stack([torch.tensor(dataprocessor.embeddings_dict['embedding'][lab.item()]) for lab in padded_true_horizon_indices.view(-1) if lab != -1]).to(device)\n",
    "    true_horizon_indices = padded_true_horizon_indices.view(-1)[padded_true_horizon_indices.view(-1) != -1]\n",
    "    \n",
    "    horizon_correct      += hor_topk_acc(1)(pred_horizon_embeddings, true_horizon_indices)\n",
    "    horizon_topk_correct += hor_topk_acc(hor_topk)(pred_horizon_embeddings, true_horizon_indices)\n",
    "    \n",
    "    all_topk_horizon_predictions.append(pred_topk_horizon_indices.cpu())\n",
    "    all_horizon_labels.append(true_horizon_indices.cpu())\n",
    "\n",
    "# Average IoU and horizon accuracies\n",
    "iou /= len(test_loader)\n",
    "eval_horizon_acc      = horizon_correct / len(test_loader)\n",
    "eval_horizon_topk_acc = horizon_topk_correct / len(test_loader)\n",
    "\n",
    "all_horizon_labels = torch.cat(all_horizon_labels).numpy()\n",
    "\n",
    "top1_horizon_predictions = torch.cat(all_topk_horizon_predictions)[:, 0]\n",
    "topk_horizon_predictions = torch.cat(all_topk_horizon_predictions)\n",
    "\n",
    "precision_at_k, recall_at_k = precision_recall_at_k(all_horizon_labels, topk_horizon_predictions.numpy(), \n",
    "                                                    all_labels=hor_possible_labels, average=hor_class_average)\n",
    "prec = precision_score(all_horizon_labels, top1_horizon_predictions.numpy(), \n",
    "                    labels=hor_possible_labels, average=hor_class_average, zero_division=0)\n",
    "rec  = recall_score(all_horizon_labels, top1_horizon_predictions.numpy(), \n",
    "                    labels=hor_possible_labels, average=hor_class_average, zero_division=0)\n",
    "f1   = f1_score(all_horizon_labels, top1_horizon_predictions.numpy(), \n",
    "                labels=hor_possible_labels, average=hor_class_average, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd550c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth IoU: 0.0013\n",
      "Horizon accuracy: 0.0004\n",
      "Horizon top-5 accuracy: 0.0007\n",
      "Precision: 0.0017\n",
      "Recall: 0.0100\n",
      "Precision at 5: 0.0120\n",
      "Recall at 5: 0.0200\n",
      "F1 score: 0.0029\n"
     ]
    }
   ],
   "source": [
    "# Check metrics\n",
    "print(f\"Depth IoU: {iou:.4f}\")\n",
    "print(f\"Horizon accuracy: {eval_horizon_acc:.4f}\")\n",
    "print(f\"Horizon top-{hor_topk} accuracy: {eval_horizon_topk_acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"Precision at {hor_topk}: {precision_at_k:.4f}\")\n",
    "print(f\"Recall at {hor_topk}: {recall_at_k:.4f}\")\n",
    "print(f\"F1 score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd79455",
   "metadata": {},
   "source": [
    "#### Horizon, cross entropy, ResNet segment encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cba497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchiaburu/anaconda3/envs/torch2_1_gpu_bgr/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "iou = 0.0\n",
    "horizon_correct = 0\n",
    "horizon_topk_correct = 0\n",
    "label_embeddings_tensor = torch.tensor(dataprocessor.embeddings_dict['embedding'], device=device).float()\n",
    "hor_topk = 5\n",
    "hor_class_average = 'macro'\n",
    "hor_possible_labels = list(range(label_embeddings_tensor.size(0)))\n",
    "all_horizon_labels = []\n",
    "all_topk_horizon_predictions = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    padded_images, image_mask, geotemp_features, padded_true_depths, padded_segments_tabulars_labels, padded_true_horizon_indices = batch\n",
    "    padded_images, image_mask, geotemp_features, padded_true_depths, padded_segments_tabulars_labels, padded_true_horizon_indices = (\n",
    "        padded_images.to(device),\n",
    "        image_mask.to(device),\n",
    "        geotemp_features.to(device),\n",
    "        padded_true_depths.to(device),\n",
    "        padded_segments_tabulars_labels.to(device),\n",
    "        padded_true_horizon_indices.to(device)\n",
    "    )\n",
    "    \n",
    "    # Mask for valid indices\n",
    "    mask = padded_true_horizon_indices != -1\n",
    "    \n",
    "    ### TASK 1: Predict depth markers based on concatenated vector\n",
    "    pred_depth_markers = depth_predictor(padded_images, image_mask, geotemp_features[:, 1:]) # 'index' column not used in model\n",
    "    \n",
    "    ### TASK 2: Predict tabular features for each segment\n",
    "    # Crop image to segments\n",
    "    segments = extract_segments(padded_images, image_mask, pred_depth_markers,\n",
    "                                segments_random_patches=tabular_predictor.predefined_random_patches, # True, use ResNet segment encoder\n",
    "                                patch_cnn_segment_size=None, # not needed for ResNet segment encoder\n",
    "                                \n",
    "                                num_patches_per_segment=48,\n",
    "                                segment_random_patch_size=224, \n",
    "                                # Note: these two attributes are available in SegmentPatchesTabularDataset when training the simple tabular, \n",
    "                                # bot not in ImageTabularEnd2EndDataset when training SoilNet (there, they are attributes of the model itself)\n",
    "                                \n",
    "                                stop_token=depth_predictor.stop_token,\n",
    "                                max_seq_len=depth_predictor.depth_marker_predictor.max_seq_len)\n",
    "    \n",
    "    tabular_predictions = tabular_predictor(segments, geotemp_features[:, 1:]) # 'index' column not used in model\n",
    "    \n",
    "    ### TASK 3: Compute horizon embedding from the final concatenated vector\n",
    "    # Concatenate tabular features from dictionary\n",
    "    processed_tabular_features = torch.cat([tabular_predictions[key] for key in tabular_predictor.tabular_predictors.keys()], dim=-1)\n",
    "\n",
    "    padded_pred_logits = horizon_resnet_ce_predictor(segments, processed_tabular_features, geotemp_features[:, 1:]) \n",
    "    pred_logits = padded_pred_logits.view(-1, padded_pred_logits.size(-1))[mask.view(-1)]  # Apply mask\n",
    "    pred_topk_horizon_indices = torch.topk(padded_pred_logits.view(-1, padded_pred_logits.size(-1)), k=hor_topk, dim=1).indices[mask.view(-1)]  # Apply same mask\n",
    "\n",
    "    ### Compute metrics\n",
    "    # Update depth IoU separately\n",
    "    iou += depth_iou(pred_depth_markers, padded_true_depths, depth_predictor.stop_token)\n",
    "    \n",
    "    ## True horizons\n",
    "    true_horizon_indices = padded_true_horizon_indices.view(-1)[padded_true_horizon_indices.view(-1) != -1]\n",
    "    \n",
    "    horizon_correct      += top_k_accuracy(pred_logits, true_horizon_indices, 1)\n",
    "    horizon_topk_correct += top_k_accuracy(pred_logits, true_horizon_indices, hor_topk)\n",
    "    \n",
    "    all_topk_horizon_predictions.append(pred_topk_horizon_indices.cpu())\n",
    "    all_horizon_labels.append(true_horizon_indices.cpu())\n",
    "\n",
    "# Average IoU and horizon accuracies\n",
    "iou /= len(test_loader)\n",
    "eval_horizon_acc      = horizon_correct / len(test_loader)\n",
    "eval_horizon_topk_acc = horizon_topk_correct / len(test_loader)\n",
    "\n",
    "all_horizon_labels = torch.cat(all_horizon_labels).numpy()\n",
    "\n",
    "top1_horizon_predictions = torch.cat(all_topk_horizon_predictions)[:, 0]\n",
    "topk_horizon_predictions = torch.cat(all_topk_horizon_predictions)\n",
    "\n",
    "precision_at_k, recall_at_k = precision_recall_at_k(all_horizon_labels, topk_horizon_predictions.numpy(), \n",
    "                                                    all_labels=hor_possible_labels, average=hor_class_average)\n",
    "prec = precision_score(all_horizon_labels, top1_horizon_predictions.numpy(), \n",
    "                    labels=hor_possible_labels, average=hor_class_average, zero_division=0)\n",
    "rec  = recall_score(all_horizon_labels, top1_horizon_predictions.numpy(), \n",
    "                    labels=hor_possible_labels, average=hor_class_average, zero_division=0)\n",
    "f1   = f1_score(all_horizon_labels, top1_horizon_predictions.numpy(), \n",
    "                labels=hor_possible_labels, average=hor_class_average, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3aa1a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth IoU: 0.0011\n",
      "Horizon accuracy: 0.0007\n",
      "Horizon top-5 accuracy: 0.0011\n",
      "Precision: 0.0050\n",
      "Recall: 0.0100\n",
      "Precision at 5: 0.0150\n",
      "Recall at 5: 0.0200\n",
      "F1 score: 0.0067\n"
     ]
    }
   ],
   "source": [
    "# Check metrics\n",
    "print(f\"Depth IoU: {iou:.4f}\")\n",
    "print(f\"Horizon accuracy: {eval_horizon_acc:.4f}\")\n",
    "print(f\"Horizon top-{hor_topk} accuracy: {eval_horizon_topk_acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"Precision at {hor_topk}: {precision_at_k:.4f}\")\n",
    "print(f\"Recall at {hor_topk}: {recall_at_k:.4f}\")\n",
    "print(f\"F1 score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2_1_gpu_bgr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
