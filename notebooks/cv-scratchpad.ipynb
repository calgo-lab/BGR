{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f71f8-8dba-4d77-a2c8-58ab5d227a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data_horizons.csv', sep=';').dropna(subset=['Bodenart'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdcbfe2-ecbe-4350-905c-805406b6d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529dea37-d848-47b1-9bba-d1ac09e44560",
   "metadata": {},
   "source": [
    "# ChatGPT Input:\n",
    "\n",
    "```can you write me some python code to finetune a dinov2 checkpoint from hugging face on a computer vision classification task?\n",
    "```\n",
    "# ChatGPT Output:\n",
    "\n",
    "Sure! Here’s a step-by-step guide and Python code for fine-tuning a DINOv2 model (from Hugging Face) for a computer vision classification task using PyTorch and the Hugging Face Transformers library.\n",
    "\n",
    "## Steps to follow:\n",
    "\n",
    "\n",
    "* Install the necessary libraries.\n",
    "* Prepare the dataset for image classification.\n",
    "* Load a pre-trained DINOv2 model from Hugging Face.\n",
    "* Prepare the model for fine-tuning.\n",
    "* Train the model on the dataset.\n",
    "* Evaluate the performance.\n",
    "\n",
    "Let’s go through the steps with Python code.\n",
    "\n",
    "### Step 1: Install Required Libraries\n",
    "First, ensure that you have the necessary libraries installed. You can install them using pip:\n",
    "\n",
    "``` pip install transformers datasets torch torchvision evaluate```\n",
    "\n",
    "### Step 2: Load Dataset\n",
    "\n",
    "* Step 1: Set Up the DataFrame\n",
    "Assume that your pandas DataFrame has two columns:\n",
    "\n",
    "image_path: This contains the full path (or relative path) to each image file.\n",
    "\n",
    "label: This contains the corresponding label for each image.\n",
    "\n",
    "* Step 2: Custom Dataset Class\n",
    "Now, we’ll write a custom PyTorch Dataset that reads from the DataFrame. The Dataset will:\n",
    "\n",
    "Load the image from the given file path.\n",
    "Apply transformations (e.g., resize, normalize).\n",
    "Return the image along with its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9008e09-460e-4821-b57c-d1712a5659cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the image transformations (resize, convert to tensor, normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "])\n",
    "\n",
    "# Custom Dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): A pandas DataFrame with 'image_path' and 'label' columns.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples\"\"\"\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Retrieves the image and label by index\"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Get the image path and label from the DataFrame\n",
    "        img_path = self.dataframe.iloc[idx]['image_path']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "\n",
    "        # Open the image file\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Convert image to RGB if it isn't already\n",
    "\n",
    "        # Apply the optional transforms (like resize and normalization)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = ImageDataset(df, transform=transform)\n",
    "\n",
    "# Example: Get the first image and label from the dataset\n",
    "img, label = dataset[0]\n",
    "print(f\"Image size: {img.size()}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462ef39-7e19-4824-8c58-ac920b0c2e23",
   "metadata": {},
   "source": [
    "### Step 3: DataLoader for Batching\n",
    "Once we have the Dataset, we can use DataLoader to create batches of images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727f6bf0-f3be-47c6-8572-f2186813bed8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Iterate through the dataloader (example)\n",
    "for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(f\"Images shape: {images.shape}, Labels shape: {labels.shape}\")\n",
    "    # Perform your training loop here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f55fed-fdc4-4dc1-b805-cb8f26e3939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the image transforms (resize, normalize, etc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 as expected by ViT models\n",
    "    transforms.ToTensor(),          # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize with ImageNet statistics\n",
    "])\n",
    "\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "# Load pre-trained DINOv2 model\n",
    "model_name = \"facebook/dinov2-vitb14\"\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_classes,  # Use the number of classes from your custom dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b2d7fa-1ad3-425b-86ec-25e02f2466e9",
   "metadata": {},
   "source": [
    "## legacy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cdf86f-4e96-4a4b-83e3-31c603073da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "###parameters to adapt to the database\n",
    "nbr_horizons = 15207\n",
    "nbr_profile = 3101\n",
    "i_h, i_w = 1500,1500  ##wanted high and width of the pictures and masks\n",
    "\n",
    "###paths\n",
    "path_csv = \"data_horizons.csv\"\n",
    "path_pictures = \"/Users/felix/Library/CloudStorage/Dropbox/data/BGR-Data-Bodenhorizonte/Profilbilder/\"\n",
    "path_images = \"images\"\n",
    "path_masks = \"masks\"\n",
    "\n",
    "\n",
    "###importation of Excel data\n",
    "data = pd.read_csv(path_csv, sep=';')\n",
    "numero = data[\"PointID\"]\n",
    "lettre = data[\"Bundesland\"]\n",
    "symboles = data[\"Horizontsymbol\"]\n",
    "hauteur_inf = data[\"Untergrenze\"]\n",
    "depthmax = data[\"max_depth\"]\n",
    "prof_hor = data[\"Point\"]\n",
    "\n",
    "### extract the main symbol from horizons names\n",
    "\n",
    "symboles_simples = []\n",
    "for k in range(nbr_horizons):\n",
    "    symb = \"\"\n",
    "    horizon = symboles[k]\n",
    "    horizon = str(horizon)\n",
    "    for car in horizon:\n",
    "        if car in \"AGSBCHMOP\":\n",
    "            symb = car\n",
    "    if symb == \"\":\n",
    "        symboles_simples += \"0\"\n",
    "    else:\n",
    "        symboles_simples += str(symb)\n",
    "\n",
    "\n",
    "#### creation list of profiles\n",
    "profile = []\n",
    "for k in range(nbr_profile):\n",
    "    if numero[k] < 10:\n",
    "        profile += [str(str(lettre[k]) + \"_000\" + str(numero[k]))]\n",
    "    elif numero[k] < 100:\n",
    "        profile += [str(str(lettre[k]) + \"_00\" + str(numero[k]))]\n",
    "    elif numero[k] < 1000:\n",
    "        profile += [str(str(lettre[k]) + \"_0\" + str(numero[k]))]\n",
    "    else:\n",
    "        profile += [str(str(lettre[k]) + \"_\" + str(numero[k]))]\n",
    "\n",
    "\n",
    "\n",
    "###creation of a list with the real depth of the bottom of the A-horizon\n",
    "\n",
    "depth_reelle = []\n",
    "k = 0\n",
    "for i in range(nbr_profile):\n",
    "    d = 0\n",
    "    profil = int(numero[i])\n",
    "    while prof_hor[k] == profil:\n",
    "        if symboles_simples[k] == \"A\" and symboles_simples[k+1] != \"A\":\n",
    "            d = hauteur_inf[k]\n",
    "        k += 1\n",
    "    if d == 0:\n",
    "        depth_reelle += [str(profile[i] + \"= 00\")]\n",
    "    elif d < 10:\n",
    "        depth_reelle += [str(profile[i] + \"= 0\" + str(int(d)))]\n",
    "    else:\n",
    "        depth_reelle += [str(profile[i] + \"= \" + str(int(d)))]\n",
    "\n",
    "depth_reelle.sort() #sorted by alphabetic order to ease the correlation between the 2 lists\n",
    "\n",
    "hauteur_image = []\n",
    "for elt in depth_reelle:\n",
    "    hauteur_image += [int(elt[-3:])] #get only the depth without the profile name\n",
    "\n",
    "\n",
    "###list of the depths in the resized pictures\n",
    "depths = []\n",
    "for k in range(nbr_profile):\n",
    "    depth = ((hauteur_image[k] * i_h)/depthmax[k])\n",
    "    depths.append(depth)\n",
    "\n",
    "\n",
    "####list images\n",
    "image_dataset = os.listdir(path_pictures)\n",
    "images = []\n",
    "# for profile in image_dataset:\n",
    "#     path = os.path.join(path_pictures, profile)\n",
    "#     img = Image.open(path).convert('RGB')\n",
    "#     images.append(img)\n",
    "\n",
    "\n",
    "###resize images and convert into array\n",
    "# y = np.zeros((nbr_profile, i_h, i_w, 1), dtype=np.int32)\n",
    "# X = np.zeros((nbr_profile, i_h, i_w,3), dtype=np.float32)\n",
    "\n",
    "# for i in range(nbr_profile) :\n",
    "#     single_img = images[i]\n",
    "\n",
    "#     single_img = single_img.resize((i_h, i_w))\n",
    "#     single_img = np.reshape(single_img, (i_h, i_w, 3))\n",
    "\n",
    "#     X[i] = single_img\n",
    "\n",
    "\n",
    "# ### create masks (that has the same dimensions of the image where each pixel is valued at 0 except for the A-horizon where pixel value = 1)\n",
    "\n",
    "# for k in range (nbr_profile):\n",
    "#     mask = np.zeros((i_h, i_w, 1), dtype=np.int32)\n",
    "#     lim = depths[k]\n",
    "\n",
    "#     if lim == 0:  #if depth =0 : no A-horizon in the profile\n",
    "#         y[k] = mask\n",
    "#     else:\n",
    "#         cv2.rectangle(mask, (0, 0), (i_w, int(lim)), 1, -1)    # assimilate horizon to a rectangle\n",
    "#         y[k] = mask\n",
    "\n",
    "# ###save mask and images as png\n",
    "# i = 1\n",
    "# j = 1\n",
    "\n",
    "# for img in X:\n",
    "#     cv2.imwrite(path_images + \"image\" + str(i) + \".png\", img)\n",
    "#     i += 1\n",
    "\n",
    "# for img in y:\n",
    "#     cv2.imwrite(path_masks + \"mask\" + str(j) + \".png\", img)\n",
    "#     j += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
